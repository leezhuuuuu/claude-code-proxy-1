# # Required: Your OpenAI API key
# OPENAI_API_KEY="sk-your-openai-api-key-here"

# # Optional: Expected Anthropic API key for client validation
# # If set, clients must provide this exact API key to access the proxy
# ANTHROPIC_API_KEY="your-expected-anthropic-api-key"

# # Optional: OpenAI API base URL (default: https://api.openai.com/v1)
# # You can change this to use other providers like Azure OpenAI, local models, etc.
# OPENAI_BASE_URL="https://api.openai.com/v1"

# # Optional: Model mappings (BIG and SMALL models)
# BIG_MODEL="gpt-4o"
# # Used for Claude opus requests
# MIDDLE_MODEL="gpt-4o"
# # Used for Claude sonnet requests
# SMALL_MODEL="gpt-4o-mini"    
# # Used for Claude haiku requests

# # Optional: Server settings
# HOST="0.0.0.0"
# PORT="8082"
# LOG_LEVEL="INFO"  
# # DEBUG, INFO, WARNING, ERROR, CRITICAL

# # Optional: Performance settings  
# MAX_TOKENS_LIMIT="4096"
# # Minimum tokens limit for requests (to avoid errors with thinking model)
# MIN_TOKENS_LIMIT="4096"
# REQUEST_TIMEOUT="90"
# MAX_RETRIES="2"

# # Examples for other providers:

# # For Azure OpenAI (recommended if OpenAI is not available in your region):
# # OPENAI_API_KEY="your-azure-api-key"
# # OPENAI_BASE_URL="https://your-resource-name.openai.azure.com/openai/deployments/your-deployment-name"
# # AZURE_API_VERSION="2024-03-01-preview"
# # BIG_MODEL="gpt-4"
# # MIDDLE_MODEL="gpt-4"
# # SMALL_MODEL="gpt-35-turbo"

# # For local models (like Ollama):
# # OPENAI_API_KEY="dummy-key"  # Required but can be any value for local models
# # OPENAI_BASE_URL="http://localhost:11434/v1"
# # BIG_MODEL="llama3.1:70b"
# # MIDDLE_MODEL="llama3.1:70b"
# # SMALL_MODEL="llama3.1:8b"

# # Note: If you get "unsupported_country_region_territory" errors,
# # consider using Azure OpenAI or a local model setup instead.
# 必填：你的 OpenAI API 密钥
OPENAI_API_KEY="Qq818308046"

# 可选：用于客户端验证的 Anthropic API 密钥
# 如果设置，客户端必须提供此密钥才能访问代理
# ANTHROPIC_API_KEY="Qq818308046"

# 可选：OpenAI API 基础 URL（默认：https://api.openai.com/v1）
# 你可以修改为其他提供商，如 Azure OpenAI、本地模型等
OPENAI_BASE_URL="https://gemini.leezhu.cn/v1"

# 可选：模型映射（大模型和小模型）
BIG_MODEL="gemini-2.5-pro"
# 用于 Claude opus 请求
MIDDLE_MODEL="gemini-2.5-pro"
# 用于 Claude sonnet 请求
SMALL_MODEL="gemini-2.5-flash"    
# 用于 Claude haiku 请求

# 可选：服务器设置
HOST="0.0.0.0"
PORT="8082"
LOG_LEVEL="INFO"  
# DEBUG, INFO, WARNING, ERROR, CRITICAL

# 可选：性能设置  
MAX_TOKENS_LIMIT="8192"
# 请求的最小 token 限制（避免思维模型报错）
MIN_TOKENS_LIMIT="8192"
REQUEST_TIMEOUT="90"
MAX_RETRIES="2"

# 其他提供商示例：

# 对于 Azure OpenAI（如果 OpenAI 在你所在地区不可用，推荐使用）：
# OPENAI_API_KEY="your-azure-api-key"
# OPENAI_BASE_URL="https://your-resource-name.openai.azure.com/openai/deployments/your-deployment-name"
# AZURE_API_VERSION="2024-03-01-preview"
# BIG_MODEL="gpt-4"
# MIDDLE_MODEL="gpt-4"
# SMALL_MODEL="gpt-35-turbo"

# 对于本地模型（如 Ollama）：
# OPENAI_API_KEY="dummy-key"  # 必填，但本地模型可任意填写
# OPENAI_BASE_URL="http://localhost:11434/v1"
# BIG_MODEL="llama3.1:70b"
# MIDDLE_MODEL="llama3.1:70b"
# SMALL_MODEL="llama3.1:8b"

# 注意：如果遇到 "unsupported_country_region_territory" 错误，
# 请考虑使用 Azure OpenAI 或本地模型方案。
